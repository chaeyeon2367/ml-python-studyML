{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaeyeon2367/ml-python-studyML/blob/main/Ensemble%20Learning%20/Stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking\n",
        "\n",
        ": It is also called \"Meta learner\", a technique that combines various models"
      ],
      "metadata": {
        "id": "Nmuwy0LVo7fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hgCxxjsMoZtA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the dataset"
      ],
      "metadata": {
        "id": "CLIwVGB0pJJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fxb6na1pPXa",
        "outputId": "df4d3b2d-7595-42bc-e8c3-c56cae7a7f20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "1xq06ePDoZtD",
        "outputId": "14bd2374-a82f-4fd0-86be-496cdb10487d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
              "0   1       1       0       0       0       0       0       0       0       0   \n",
              "1   2       0       0       0       0       0       0       0       1       0   \n",
              "2   3       0       0       0       0       0       0       0       1       0   \n",
              "3   4       1       0       0       1       6       1       5       0       0   \n",
              "4   5       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
              "0  ...        1        0        0        0        0        0        0   \n",
              "1  ...        0        0        0        0        0        0        0   \n",
              "2  ...        0        0        0        0        0        0        0   \n",
              "3  ...        0        1        2        0        0        0        0   \n",
              "4  ...        1        0        0        0        0        1        0   \n",
              "\n",
              "   feat_92  feat_93   target  \n",
              "0        0        0  Class_1  \n",
              "1        0        0  Class_1  \n",
              "2        0        0  Class_1  \n",
              "3        0        0  Class_1  \n",
              "4        0        0  Class_1  \n",
              "\n",
              "[5 rows x 95 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5410415d-7968-4f44-b112-4a83b13e9fb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>feat_1</th>\n",
              "      <th>feat_2</th>\n",
              "      <th>feat_3</th>\n",
              "      <th>feat_4</th>\n",
              "      <th>feat_5</th>\n",
              "      <th>feat_6</th>\n",
              "      <th>feat_7</th>\n",
              "      <th>feat_8</th>\n",
              "      <th>feat_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feat_85</th>\n",
              "      <th>feat_86</th>\n",
              "      <th>feat_87</th>\n",
              "      <th>feat_88</th>\n",
              "      <th>feat_89</th>\n",
              "      <th>feat_90</th>\n",
              "      <th>feat_91</th>\n",
              "      <th>feat_92</th>\n",
              "      <th>feat_93</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 95 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5410415d-7968-4f44-b112-4a83b13e9fb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5410415d-7968-4f44-b112-4a83b13e9fb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5410415d-7968-4f44-b112-4a83b13e9fb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9f189cd-fda3-427a-8529-e92b3e20fa90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9f189cd-fda3-427a-8529-e92b3e20fa90')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9f189cd-fda3-427a-8529-e92b3e20fa90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Ensemble learning/otto_train.csv\") # Product Category\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "75GDNrmkoZtD",
        "outputId": "9ab89609-4a23-40fd-da6e-81bea51fd3d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nid: unique ID\\nfeat_1 to feat_93: explanatory variable\\nTarget: Target Variables (1 to 9)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''\n",
        "id: unique ID\n",
        "feat_1 to feat_93: explanatory variable\n",
        "Target: Target Variables (1 to 9)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlENX_2aoZtE",
        "outputId": "dcba2aa7-554c-4207-8212-c7cafedee39f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nCar: 61878 nVar: 95\n"
          ]
        }
      ],
      "source": [
        "nCar = data.shape[0] # number of data\n",
        "nVar = data.shape[1] # number of variable\n",
        "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsPWW2lioZtE"
      },
      "source": [
        "## Remove variables deemed meaningless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lVctr_qmoZtF"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['id'], axis = 1) # remove id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6-UMRZtoZtF"
      },
      "source": [
        "## Convert the string of the target variable to a number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wEzxbkoOoZtF"
      },
      "outputs": [],
      "source": [
        "mapping_dict = {\"Class_1\": 1,\n",
        "                \"Class_2\": 2,\n",
        "                \"Class_3\": 3,\n",
        "                \"Class_4\": 4,\n",
        "                \"Class_5\": 5,\n",
        "                \"Class_6\": 6,\n",
        "                \"Class_7\": 7,\n",
        "                \"Class_8\": 8,\n",
        "                \"Class_9\": 9}\n",
        "after_mapping_target = data['target'].apply(lambda x: mapping_dict[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9f7hIjzoZtF"
      },
      "source": [
        "## Split explanatory and target variables, split learning and evaluation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8DsTNeHoZtG",
        "outputId": "1788854b-5e3f-4b59-c274-92d6f11c88aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49502, 93) (12376, 93) (49502,) (12376,)\n"
          ]
        }
      ],
      "source": [
        "feature_columns = list(data.columns.difference(['target']))\n",
        "X = data[feature_columns] # explantory variable\n",
        "y = after_mapping_target # target variable\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42) # split the ratio of learning data to evaluation data by 8:2\n",
        "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # Check the number of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umALc7iJoZtG"
      },
      "source": [
        "## 1. XGBoost\n",
        "\n",
        "- gradient boosting + regularization\n",
        "- prevent overfiting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "ZvVuQ0RivoBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d5b464-ff45-4e43-ca81-befc83c7b9f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG2YXg2roZtG",
        "outputId": "682923e7-d722-4c8b-bebc-91b968088c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:52:50] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 76.66 %\n",
            "Time: 15.29 seconds\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "import time\n",
        "start = time.time() # set the start time\n",
        "xgb_dtrain = xgb.DMatrix(data = train_x, label = train_y) # Convert training data to fit XGBoost model\n",
        "xgb_dtest = xgb.DMatrix(data = test_x) # Convert test data to fit XGBoost model\n",
        "xgb_param = {'max_depth': 10, # the depth of tree\n",
        "         'learning_rate': 0.01, # Step Size\n",
        "         'n_estimators': 100, # Number of trees\n",
        "         'objective': 'multi:softmax', # objecive function\n",
        "        'num_class': len(set(train_y)) + 1} # add parameter, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
        "xgb_model = xgb.train(params = xgb_param, dtrain = xgb_dtrain) # learning process\n",
        "xgb_model_predict = xgb_model.predict(xgb_dtest) # test data prediction\n",
        "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, xgb_model_predict) * 100), \"%\") # calculate accuracy\n",
        "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # Calculation of Code Execution Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug7iKrcboZtH",
        "outputId": "6e1b1516-cccc-4a71-fb6c-6690cd0a63a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5., 3., 6., ..., 9., 2., 7.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "xgb_model_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARw8zPi5oZtH"
      },
      "source": [
        "## 2. LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- binary regression : binary logistic or logistic regression"
      ],
      "metadata": {
        "id": "BzeKtIK4wvmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "VWVJn3_Ov5Mj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31659f74-507d-4136-8127-b8b2802bc88c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nP9NHGAoZtH",
        "outputId": "bb8ca6e6-e317-4646-ff4b-a49a51b77d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3110\n",
            "[LightGBM] [Info] Number of data points in the train set: 49502, number of used features: 93\n",
            "[LightGBM] [Info] Start training from score -34.538776\n",
            "[LightGBM] [Info] Start training from score -3.476745\n",
            "[LightGBM] [Info] Start training from score -1.341381\n",
            "[LightGBM] [Info] Start training from score -2.039019\n",
            "[LightGBM] [Info] Start training from score -3.135151\n",
            "[LightGBM] [Info] Start training from score -3.125444\n",
            "[LightGBM] [Info] Start training from score -1.481556\n",
            "[LightGBM] [Info] Start training from score -3.074772\n",
            "[LightGBM] [Info] Start training from score -1.986562\n",
            "[LightGBM] [Info] Start training from score -2.533374\n",
            "Accuracy: 76.28 %\n",
            "Time: 37.59 seconds\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "start = time.time()\n",
        "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # Convert training data to fit LightGBM model\n",
        "lgb_param = {'max_depth': 10, #depth of tree\n",
        "            'learning_rate': 0.01, # Step Size\n",
        "            'n_estimators': 100, # Number of trees\n",
        "            'objective': 'multiclass', # objective function\n",
        "            'num_class': len(set(train_y)) + 1} # add parameter, Label must be in [0, num_class) -> It must be 1 greater than num_class.\n",
        "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # learning process\n",
        "lgb_model_predict = np.argmax(lgb_model.predict(test_x), axis = 1) # predict test data, Predicts the largest value of the result of Softmax in Label\n",
        "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, lgb_model_predict) * 100), \"%\") # calculate accuracy\n",
        "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # Calculation of Code Execution Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RafLEnOoZtI",
        "outputId": "63b85ac9-237c-4c24-8650-9293fc71ebf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.01734061e-15, 2.25081693e-02, 3.62193933e-01, ...,\n",
              "        3.24234521e-02, 5.82126692e-02, 3.67722414e-02],\n",
              "       [1.14084116e-15, 5.36978636e-02, 1.90687128e-01, ...,\n",
              "        3.25081119e-01, 9.38028846e-02, 6.50463131e-02],\n",
              "       [5.94595781e-16, 9.66842220e-03, 5.82817482e-02, ...,\n",
              "        1.42318289e-02, 3.40230275e-02, 2.14919364e-02],\n",
              "       ...,\n",
              "       [7.09105769e-16, 4.63740004e-02, 1.08297559e-01, ...,\n",
              "        5.46934960e-02, 7.24513712e-02, 5.74635996e-01],\n",
              "       [9.88127136e-16, 1.54895684e-02, 5.45515599e-01, ...,\n",
              "        2.45870954e-02, 5.65410617e-02, 3.62344513e-02],\n",
              "       [7.59617500e-16, 1.49480877e-02, 7.44570300e-02, ...,\n",
              "        5.76695793e-01, 1.43227106e-01, 2.74567219e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "lgb_model.predict(test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4AmOkRHoZtI"
      },
      "source": [
        "## 3. Catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "h1sKG1zax1tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31168e69-8d5a-4753-87a9-781b6a44e09d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3VStuYDoZtI",
        "outputId": "a5215f2d-302e-4b5f-cafa-ef3da81b20dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.5907034\ttotal: 3.74s\tremaining: 6m 10s\n",
            "1:\tlearn: 0.6356107\ttotal: 8.1s\tremaining: 6m 36s\n",
            "2:\tlearn: 0.6411256\ttotal: 10.7s\tremaining: 5m 46s\n",
            "3:\tlearn: 0.6480344\ttotal: 13s\tremaining: 5m 12s\n",
            "4:\tlearn: 0.6508222\ttotal: 15.6s\tremaining: 4m 56s\n",
            "5:\tlearn: 0.6499939\ttotal: 19.2s\tremaining: 5m 1s\n",
            "6:\tlearn: 0.6507818\ttotal: 26s\tremaining: 5m 45s\n",
            "7:\tlearn: 0.6548422\ttotal: 29s\tremaining: 5m 33s\n",
            "8:\tlearn: 0.6559533\ttotal: 31.7s\tremaining: 5m 20s\n",
            "9:\tlearn: 0.6560947\ttotal: 34.6s\tremaining: 5m 11s\n",
            "10:\tlearn: 0.6568421\ttotal: 36.6s\tremaining: 4m 56s\n",
            "11:\tlearn: 0.6588219\ttotal: 40.2s\tremaining: 4m 54s\n",
            "12:\tlearn: 0.6592259\ttotal: 43.7s\tremaining: 4m 52s\n",
            "13:\tlearn: 0.6611248\ttotal: 45.7s\tremaining: 4m 40s\n",
            "14:\tlearn: 0.6625591\ttotal: 46.7s\tremaining: 4m 24s\n",
            "15:\tlearn: 0.6631853\ttotal: 47.7s\tremaining: 4m 10s\n",
            "16:\tlearn: 0.6639328\ttotal: 48.7s\tremaining: 3m 57s\n",
            "17:\tlearn: 0.6668821\ttotal: 49.7s\tremaining: 3m 46s\n",
            "18:\tlearn: 0.6669630\ttotal: 50.6s\tremaining: 3m 35s\n",
            "19:\tlearn: 0.6675286\ttotal: 51.6s\tremaining: 3m 26s\n",
            "20:\tlearn: 0.6673266\ttotal: 52.6s\tremaining: 3m 17s\n",
            "21:\tlearn: 0.6677104\ttotal: 53.6s\tremaining: 3m 10s\n",
            "22:\tlearn: 0.6682558\ttotal: 55.4s\tremaining: 3m 5s\n",
            "23:\tlearn: 0.6683972\ttotal: 57.2s\tremaining: 3m 1s\n",
            "24:\tlearn: 0.6686599\ttotal: 59.1s\tremaining: 2m 57s\n",
            "25:\tlearn: 0.6681952\ttotal: 1m\tremaining: 2m 52s\n",
            "26:\tlearn: 0.6684982\ttotal: 1m 1s\tremaining: 2m 46s\n",
            "27:\tlearn: 0.6692053\ttotal: 1m 2s\tremaining: 2m 41s\n",
            "28:\tlearn: 0.6696699\ttotal: 1m 4s\tremaining: 2m 38s\n",
            "29:\tlearn: 0.6699325\ttotal: 1m 6s\tremaining: 2m 35s\n",
            "30:\tlearn: 0.6705992\ttotal: 1m 7s\tremaining: 2m 30s\n",
            "31:\tlearn: 0.6709426\ttotal: 1m 8s\tremaining: 2m 25s\n",
            "32:\tlearn: 0.6708012\ttotal: 1m 9s\tremaining: 2m 21s\n",
            "33:\tlearn: 0.6709426\ttotal: 1m 10s\tremaining: 2m 17s\n",
            "34:\tlearn: 0.6707002\ttotal: 1m 12s\tremaining: 2m 14s\n",
            "35:\tlearn: 0.6715082\ttotal: 1m 14s\tremaining: 2m 11s\n",
            "36:\tlearn: 0.6705992\ttotal: 1m 16s\tremaining: 2m 9s\n",
            "37:\tlearn: 0.6725991\ttotal: 1m 17s\tremaining: 2m 6s\n",
            "38:\tlearn: 0.6729829\ttotal: 1m 18s\tremaining: 2m 3s\n",
            "39:\tlearn: 0.6725991\ttotal: 1m 19s\tremaining: 1m 59s\n",
            "40:\tlearn: 0.6734273\ttotal: 1m 20s\tremaining: 1m 56s\n",
            "41:\tlearn: 0.6738314\ttotal: 1m 21s\tremaining: 1m 52s\n",
            "42:\tlearn: 0.6741546\ttotal: 1m 23s\tremaining: 1m 50s\n",
            "43:\tlearn: 0.6739728\ttotal: 1m 24s\tremaining: 1m 47s\n",
            "44:\tlearn: 0.6741950\ttotal: 1m 25s\tremaining: 1m 44s\n",
            "45:\tlearn: 0.6750636\ttotal: 1m 26s\tremaining: 1m 41s\n",
            "46:\tlearn: 0.6758919\ttotal: 1m 27s\tremaining: 1m 39s\n",
            "47:\tlearn: 0.6757707\ttotal: 1m 29s\tremaining: 1m 37s\n",
            "48:\tlearn: 0.6762151\ttotal: 1m 31s\tremaining: 1m 35s\n",
            "49:\tlearn: 0.6774474\ttotal: 1m 33s\tremaining: 1m 33s\n",
            "50:\tlearn: 0.6777100\ttotal: 1m 34s\tremaining: 1m 31s\n",
            "51:\tlearn: 0.6786594\ttotal: 1m 35s\tremaining: 1m 28s\n",
            "52:\tlearn: 0.6789827\ttotal: 1m 36s\tremaining: 1m 25s\n",
            "53:\tlearn: 0.6804372\ttotal: 1m 37s\tremaining: 1m 23s\n",
            "54:\tlearn: 0.6804372\ttotal: 1m 38s\tremaining: 1m 20s\n",
            "55:\tlearn: 0.6809220\ttotal: 1m 39s\tremaining: 1m 18s\n",
            "56:\tlearn: 0.6812250\ttotal: 1m 40s\tremaining: 1m 16s\n",
            "57:\tlearn: 0.6813058\ttotal: 1m 41s\tremaining: 1m 13s\n",
            "58:\tlearn: 0.6811846\ttotal: 1m 42s\tremaining: 1m 11s\n",
            "59:\tlearn: 0.6813260\ttotal: 1m 43s\tremaining: 1m 9s\n",
            "60:\tlearn: 0.6816694\ttotal: 1m 44s\tremaining: 1m 7s\n",
            "61:\tlearn: 0.6823159\ttotal: 1m 46s\tremaining: 1m 5s\n",
            "62:\tlearn: 0.6832653\ttotal: 1m 48s\tremaining: 1m 3s\n",
            "63:\tlearn: 0.6840734\ttotal: 1m 50s\tremaining: 1m 2s\n",
            "64:\tlearn: 0.6840734\ttotal: 1m 51s\tremaining: 1m\n",
            "65:\tlearn: 0.6846592\ttotal: 1m 52s\tremaining: 58.1s\n",
            "66:\tlearn: 0.6843360\ttotal: 1m 53s\tremaining: 56s\n",
            "67:\tlearn: 0.6846390\ttotal: 1m 54s\tremaining: 54s\n",
            "68:\tlearn: 0.6854269\ttotal: 1m 55s\tremaining: 52s\n",
            "69:\tlearn: 0.6858309\ttotal: 1m 56s\tremaining: 50s\n",
            "70:\tlearn: 0.6858309\ttotal: 1m 57s\tremaining: 48.1s\n",
            "71:\tlearn: 0.6865783\ttotal: 1m 58s\tremaining: 46.1s\n",
            "72:\tlearn: 0.6864167\ttotal: 1m 59s\tremaining: 44.2s\n",
            "73:\tlearn: 0.6868611\ttotal: 2m\tremaining: 42.4s\n",
            "74:\tlearn: 0.6869217\ttotal: 2m 1s\tremaining: 40.5s\n",
            "75:\tlearn: 0.6870429\ttotal: 2m 3s\tremaining: 39s\n",
            "76:\tlearn: 0.6875278\ttotal: 2m 5s\tremaining: 37.5s\n",
            "77:\tlearn: 0.6881136\ttotal: 2m 7s\tremaining: 36s\n",
            "78:\tlearn: 0.6883762\ttotal: 2m 8s\tremaining: 34.3s\n",
            "79:\tlearn: 0.6888207\ttotal: 2m 9s\tremaining: 32.5s\n",
            "80:\tlearn: 0.6892449\ttotal: 2m 10s\tremaining: 30.7s\n",
            "81:\tlearn: 0.6898509\ttotal: 2m 11s\tremaining: 28.9s\n",
            "82:\tlearn: 0.6897095\ttotal: 2m 13s\tremaining: 27.3s\n",
            "83:\tlearn: 0.6902549\ttotal: 2m 14s\tremaining: 25.5s\n",
            "84:\tlearn: 0.6909822\ttotal: 2m 15s\tremaining: 23.8s\n",
            "85:\tlearn: 0.6910832\ttotal: 2m 16s\tremaining: 22.2s\n",
            "86:\tlearn: 0.6914468\ttotal: 2m 17s\tremaining: 20.5s\n",
            "87:\tlearn: 0.6916084\ttotal: 2m 18s\tremaining: 18.8s\n",
            "88:\tlearn: 0.6919922\ttotal: 2m 19s\tremaining: 17.2s\n",
            "89:\tlearn: 0.6925579\ttotal: 2m 21s\tremaining: 15.7s\n",
            "90:\tlearn: 0.6928407\ttotal: 2m 23s\tremaining: 14.2s\n",
            "91:\tlearn: 0.6930427\ttotal: 2m 25s\tremaining: 12.6s\n",
            "92:\tlearn: 0.6935073\ttotal: 2m 26s\tremaining: 11s\n",
            "93:\tlearn: 0.6940932\ttotal: 2m 27s\tremaining: 9.39s\n",
            "94:\tlearn: 0.6944972\ttotal: 2m 28s\tremaining: 7.8s\n",
            "95:\tlearn: 0.6948810\ttotal: 2m 29s\tremaining: 6.21s\n",
            "96:\tlearn: 0.6951840\ttotal: 2m 30s\tremaining: 4.64s\n",
            "97:\tlearn: 0.6954264\ttotal: 2m 31s\tremaining: 3.09s\n",
            "98:\tlearn: 0.6955881\ttotal: 2m 32s\tremaining: 1.54s\n",
            "99:\tlearn: 0.6956285\ttotal: 2m 33s\tremaining: 0us\n",
            "Accuracy: 69.64 %\n",
            "Time: 153.98 seconds\n"
          ]
        }
      ],
      "source": [
        "import catboost as cb\n",
        "start = time.time()\n",
        "cb_dtrain = cb.Pool(data = train_x, label = train_y) # Convert training data to fit Catboost model\n",
        "cb_param = {'max_depth': 10, # depth of tree\n",
        "            'learning_rate': 0.01, # Step Size\n",
        "            'n_estimators': 100, # Number of trees\n",
        "            'eval_metric': 'Accuracy', # evaluation of metric\n",
        "            'loss_function': 'MultiClass'} # loss fuction, objective function\n",
        "cb_model = cb.train(pool = cb_dtrain, params = cb_param) # learning process\n",
        "cb_model_predict = np.argmax(cb_model.predict(test_x), axis = 1) + 1 #Evaluate test data prediction, the largest label of Softmax's results, +1 to match the order of indexes\n",
        "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, cb_model_predict) * 100), \"%\") # caculate accuracy\n",
        "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # calculate execution time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftLgKKFuoZtI",
        "outputId": "ad2e8623-ba03-4db1-a4b9-405ade218853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.35426047,  1.22109587,  0.44230101, ..., -0.1698448 ,\n",
              "        -0.02059177, -0.2130643 ],\n",
              "       [-0.07235138,  0.42535181,  0.20060428, ...,  0.21863604,\n",
              "         0.2719157 ,  0.25089315],\n",
              "       [-0.3315885 , -0.31862353, -0.31279765, ..., -0.29798357,\n",
              "        -0.24018767, -0.32984969],\n",
              "       ...,\n",
              "       [ 0.05304325,  0.02500267, -0.14752573, ..., -0.20741963,\n",
              "         0.12789417,  1.51166757],\n",
              "       [-0.55093666,  1.7691278 ,  0.99746884, ..., -0.3420542 ,\n",
              "        -0.49799871, -0.38136323],\n",
              "       [-0.3033724 ,  0.09352675, -0.11808658, ...,  0.65825036,\n",
              "         1.05515787, -0.20799899]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "cb_model.predict(test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset - house price dataset"
      ],
      "metadata": {
        "id": "8p66ENk8sWwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "B28_wf0qoZtI",
        "outputId": "16140756-1372-4c4f-9d9a-32ba75ebc330"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id             date     price  bedrooms  bathrooms  floors  \\\n",
              "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
              "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
              "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
              "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
              "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
              "\n",
              "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
              "0           0          3      7      1955             0    98178  47.5112   \n",
              "1           0          3      7      1951          1991    98125  47.7210   \n",
              "2           0          3      6      1933             0    98028  47.7379   \n",
              "3           0          5      7      1965             0    98136  47.5208   \n",
              "4           0          3      8      1987             0    98074  47.6168   \n",
              "\n",
              "      long  \n",
              "0 -122.257  \n",
              "1 -122.319  \n",
              "2 -122.233  \n",
              "3 -122.393  \n",
              "4 -122.045  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f7e49de-0ec9-48d7-8983-e3476fa79c28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f7e49de-0ec9-48d7-8983-e3476fa79c28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f7e49de-0ec9-48d7-8983-e3476fa79c28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f7e49de-0ec9-48d7-8983-e3476fa79c28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-faafdf86-ede2-40dc-9403-ea2f822851f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-faafdf86-ede2-40dc-9403-ea2f822851f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-faafdf86-ede2-40dc-9403-ea2f822851f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# import dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Ensemble learning/kc_house_data.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "i6y0lv1boZtJ"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis = 1) # id, date, zipcode, lat, long remove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIaE11q1oZtJ",
        "outputId": "fe747bbd-a125-448d-8f72-40133c61d2ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15129, 8) (6484, 8) (15129,) (6484,)\n"
          ]
        }
      ],
      "source": [
        "feature_columns = list(data.columns.difference(['price'])) # All rows except Price colum\n",
        "X = data[feature_columns]\n",
        "y = data['price']\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # The ratio of train data to test data is 7:3\n",
        "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble of Ensemble"
      ],
      "metadata": {
        "id": "EDJHPiLrzsEA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5acnnWPoZtJ",
        "outputId": "3d5ee37c-5615-4855-918f-7320fc255f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 237\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 537729.263666\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "start = time.time()\n",
        "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # Convert training data to fit LightGBM model\n",
        "lgb_param = {'max_depth': 10, #depth of tree\n",
        "            'learning_rate': 0.01, # Step Size\n",
        "            'n_estimators': 500, # Number of trees\n",
        "            'objective': 'regression'} # add parameter, Label must be in [0, num_class) -> It must be 1 greater than num_class\n",
        "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # learning process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjsSEDeroZtJ",
        "outputId": "3d498d97-84bf-4775-e670-fa52c5bc9096"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210904.17249451784"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "sqrt(mean_squared_error(lgb_model.predict(test_x),test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skWXkQGQoZtJ",
        "outputId": "3216601c-bba6-4785-8382-902c720b551f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9559\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.157996 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 537509.363210\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "9534\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 233\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 535648.812149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9586\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 235\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 534865.791658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "9515\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 230\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 539142.813603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9487\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 229\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 537785.704475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9488\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 536765.056514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9609\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 236\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 537161.988895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9560\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 235\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 539179.565074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9594\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 233\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 541297.128495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9554\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 536844.896622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9566\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146200 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 231\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 534841.135501\n",
            "9541\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 538922.173045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9517\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 539048.196180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9522\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 538360.215348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9529\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 233\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 538360.122612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "9591\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 233\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 534996.971313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9613\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 233\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 538877.429903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9579\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 231\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 538177.533214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9510\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 233\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 539213.572212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9567\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 234\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 544006.210523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "9626\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 234\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 539258.026241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9642\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 231\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 536164.172582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9524\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 234\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 539734.599709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9599\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 230\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 539197.816049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "9522\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 231\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 533376.688281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9567\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 233\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 536648.774671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9652\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 540147.854650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "9590\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 234\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 538265.597330\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "9501\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006894 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 234\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 535857.940181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9592\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 232\n",
            "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 542746.585432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "bagging_predict_result = [] # create bin list\n",
        "for _ in range(30):\n",
        "    data_index = [data_index for data_index in range(train_x.shape[0])] # Convert the index of the learning data to a list\n",
        "    random_data_index = np.random.choice(data_index, train_x.shape[0]) # Random sampling as much as 1/10th the size of the data, // to ignore the decimal point\n",
        "    print(len(set(random_data_index)))\n",
        "    lgb_dtrain = lgb.Dataset(data = train_x.iloc[random_data_index,], label = train_y.iloc[random_data_index,]) # Convert training data to fit LightGBM model\n",
        "    lgb_param = {'max_depth': 10, # depth of tree\n",
        "            'learning_rate': 0.01, # Step Size\n",
        "            'n_estimators': 500, # Number of trees\n",
        "            'objective': 'regression'} # add parameter, Label must be in [0, num_class) -> It must be 1 greater than num_class\n",
        "    lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # learning process\n",
        "    predict1 = lgb_model.predict(test_x) # prdict test data\n",
        "    bagging_predict_result.append(predict1) # Save the result value to an empty list before the iteration runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uctcScCRoZtJ",
        "outputId": "0dd4abbc-1255-44a5-ec90-ad1db834fc15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([512599.08758705, 598322.12883382, 946813.82945502, ...,\n",
              "        337387.75778676, 932415.10447851, 473044.63932076]),\n",
              " array([489880.43845209, 682722.87489013, 917371.83201361, ...,\n",
              "        341750.13115847, 944755.18007486, 471362.41002004]),\n",
              " array([518854.32495808, 626583.99340064, 948555.1777359 , ...,\n",
              "        327559.34181381, 864015.00366211, 463030.40590377]),\n",
              " array([500018.77131601, 629177.74673737, 899376.86337203, ...,\n",
              "        354152.32476082, 910769.51958086, 462423.71342844]),\n",
              " array([515918.01324145, 659464.58846516, 934146.91771972, ...,\n",
              "        335141.08193343, 945775.85008374, 454840.72149468]),\n",
              " array([488500.22618356, 585777.09663709, 984543.28273783, ...,\n",
              "        338790.92190519, 936847.57437988, 469941.14204566]),\n",
              " array([504664.36747129, 591910.04362272, 964815.86177932, ...,\n",
              "        344398.28263172, 893999.01994994, 455135.76263881]),\n",
              " array([509083.46615529, 616074.37882989, 953179.2923477 , ...,\n",
              "        321564.1808725 , 924764.87575067, 455925.67656199]),\n",
              " array([514463.96163664, 619971.56313328, 963937.92883121, ...,\n",
              "        341129.38428729, 897444.57501689, 476823.63638311]),\n",
              " array([467631.79991738, 598705.70741026, 937442.37017849, ...,\n",
              "        319530.77567256, 895925.50209021, 456120.40207659]),\n",
              " array([510778.27618399, 661009.87655801, 905880.13964013, ...,\n",
              "        327884.7273991 , 879601.0266142 , 455498.06242908]),\n",
              " array([522364.18088572, 646197.74149756, 925351.24211682, ...,\n",
              "        341722.34785327, 927135.21415961, 468854.78649009]),\n",
              " array([512550.46615148, 587593.09041502, 942208.58533769, ...,\n",
              "        353120.27653355, 894100.29701496, 475686.48756538]),\n",
              " array([ 535881.84315371,  721482.76629299, 1006459.63769083, ...,\n",
              "         335552.34366685,  899826.52017671,  457164.42127154]),\n",
              " array([536389.80406266, 663618.42612251, 979808.89629574, ...,\n",
              "        335167.32363152, 913158.57949672, 468859.7775537 ]),\n",
              " array([506100.09114744, 600978.23979772, 923214.56162965, ...,\n",
              "        332784.57290254, 915141.9817436 , 454423.89309856]),\n",
              " array([500910.87516592, 641507.50497102, 890846.3190501 , ...,\n",
              "        336116.21671626, 918982.95274515, 461003.87642816]),\n",
              " array([493016.00145073, 680032.13943624, 985443.29504278, ...,\n",
              "        346169.88915932, 934689.87838538, 451617.99798806]),\n",
              " array([490385.00581374, 588173.38381342, 937560.48180494, ...,\n",
              "        335825.80880037, 895560.75534791, 450984.58563229]),\n",
              " array([517363.7124935 , 670788.95436199, 903185.84672744, ...,\n",
              "        323277.6283604 , 949538.06969414, 455014.12545063]),\n",
              " array([ 511386.06779267,  613662.99327911,  996739.08314647, ...,\n",
              "         365817.41116807, 1009565.47688856,  460135.57066461]),\n",
              " array([515684.10965455, 635615.09299437, 984945.05654196, ...,\n",
              "        344868.66900117, 921417.57284332, 471099.04762929]),\n",
              " array([483675.67984681, 634517.12832787, 972142.51733024, ...,\n",
              "        357523.44292853, 890820.38177883, 457196.01031254]),\n",
              " array([ 519380.99365935,  633906.76941545, 1027349.62127873, ...,\n",
              "         336232.15968043,  882859.16312778,  455934.84032044]),\n",
              " array([500011.48658396, 656300.74774422, 953911.69603625, ...,\n",
              "        338004.74167102, 885804.19952903, 458750.48330147]),\n",
              " array([495923.78722988, 558023.58223301, 909423.90108374, ...,\n",
              "        349340.97119695, 979880.45192809, 482845.32089429]),\n",
              " array([ 502773.76509765,  581259.17660336, 1013262.98125974, ...,\n",
              "         340290.78117272,  903384.52858687,  455641.71524877]),\n",
              " array([ 513217.80314271,  621518.16958497,  906715.31728173, ...,\n",
              "         330204.72452406, 1047378.45762301,  456403.6791938 ]),\n",
              " array([507279.88670121, 604020.71555375, 918999.66527796, ...,\n",
              "        356746.9981915 , 958491.31158832, 467763.36407433]),\n",
              " array([ 498443.89437854,  668805.71345204, 1009880.68377123, ...,\n",
              "         341424.66636323,  900153.07371684,  468819.11866748])]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "bagging_predict_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average for the predicted result based on Bagging\n",
        "bagging_predict = []\n",
        "for lst2_index in range(test_x.shape[0]): # Repeat as many test data\n",
        "    temp_predict = [] # Create a temporary bin list (save results in repeat statements)\n",
        "    for lst_index in range(len(bagging_predict_result)): # Repeating Bagging Results List\n",
        "        temp_predict.append(bagging_predict_result[lst_index][lst2_index]) # Store the same index in the list among the predicted values of each Bagging result\n",
        "    bagging_predict.append(np.mean(temp_predict)) # Add an average of 30 results for that index to the final list\n"
      ],
      "metadata": {
        "id": "YL5PQox21p58"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy2q5u-foZtK",
        "outputId": "1c444936-4a7c-44c9-ca19-f0a41a704873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 209726.95528929433\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average of the predicted results and evaluate the performance against the target variables of the actual test data\n",
        "\n",
        "print(\"RMSE: {}\".format(sqrt(mean_squared_error(bagging_predict, test_y)))) # RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEwv8E-QoZtK",
        "outputId": "ef5ff07c-4d2b-4a64-ab64-c8e8c8100ae6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[506504.4062505013,\n",
              " 629257.4111471666,\n",
              " 951450.429483833,\n",
              " 1585280.0524766587,\n",
              " 639637.5375683043,\n",
              " 368434.82833934244,\n",
              " 706204.9623602072,\n",
              " 431284.0225396362,\n",
              " 462014.2712649255,\n",
              " 493459.4907652565,\n",
              " 630906.8124588352,\n",
              " 381702.54442719225,\n",
              " 298452.58168299985,\n",
              " 359096.21868304454,\n",
              " 344301.7528210298,\n",
              " 1304736.710504916,\n",
              " 367010.0909092653,\n",
              " 1001925.1771924167,\n",
              " 314497.3406970689,\n",
              " 527034.7163261533,\n",
              " 377881.14684049337,\n",
              " 1836075.9051210915,\n",
              " 664169.433947043,\n",
              " 541059.1964453536,\n",
              " 510578.24996276456,\n",
              " 483686.19574299944,\n",
              " 295860.54114217986,\n",
              " 249083.10633832504,\n",
              " 472462.3020630078,\n",
              " 539056.9944383901,\n",
              " 490190.62589055835,\n",
              " 473524.8020202073,\n",
              " 463413.66200750443,\n",
              " 581582.8254885883,\n",
              " 377988.5651226484,\n",
              " 1032259.1653789232,\n",
              " 889350.676466804,\n",
              " 529410.3228323862,\n",
              " 357424.7447329129,\n",
              " 1527653.3652813279,\n",
              " 395235.33133952715,\n",
              " 277534.6994603167,\n",
              " 504964.9858223442,\n",
              " 341412.22861615766,\n",
              " 253454.26745686668,\n",
              " 243772.92851489334,\n",
              " 330641.06265385647,\n",
              " 333785.35637646355,\n",
              " 354481.13863910164,\n",
              " 573482.9190425395,\n",
              " 369288.3601464468,\n",
              " 342784.78041851573,\n",
              " 776331.7659067257,\n",
              " 335817.0876898389,\n",
              " 464202.1245379928,\n",
              " 1700320.8087218986,\n",
              " 473990.06525147206,\n",
              " 703343.3719189174,\n",
              " 332583.0952835011,\n",
              " 654776.7306055591,\n",
              " 476262.9941909369,\n",
              " 375060.6475028247,\n",
              " 298973.95795187727,\n",
              " 522580.8446848119,\n",
              " 451025.48288950906,\n",
              " 284419.7556504252,\n",
              " 384856.71731608524,\n",
              " 1582599.8706099552,\n",
              " 480926.98073258635,\n",
              " 666328.4737982161,\n",
              " 433688.2551400408,\n",
              " 298617.0607103819,\n",
              " 760748.6642933291,\n",
              " 510260.3226837451,\n",
              " 511113.5076677485,\n",
              " 1285602.8331830243,\n",
              " 814203.9348333871,\n",
              " 286486.10138731834,\n",
              " 453410.78287040215,\n",
              " 926935.2616388507,\n",
              " 638635.9635880175,\n",
              " 376409.64843958773,\n",
              " 656338.5017348645,\n",
              " 359286.68150491465,\n",
              " 831489.7793446276,\n",
              " 524607.9059190047,\n",
              " 518402.71627085865,\n",
              " 557231.5528212023,\n",
              " 358783.8201416851,\n",
              " 463137.8459832478,\n",
              " 348363.88844344456,\n",
              " 392784.0283503974,\n",
              " 641038.7534126479,\n",
              " 1075202.35653881,\n",
              " 427263.96658686677,\n",
              " 493531.64228390355,\n",
              " 361111.5337181069,\n",
              " 307790.06580765155,\n",
              " 821434.1012532228,\n",
              " 455411.4760228656,\n",
              " 255848.8960801855,\n",
              " 915337.221599966,\n",
              " 996681.2916824935,\n",
              " 479851.5577386445,\n",
              " 1057392.0689269132,\n",
              " 298393.7245970549,\n",
              " 488995.6991577195,\n",
              " 483847.9581837285,\n",
              " 813642.5649165863,\n",
              " 2399914.8609861233,\n",
              " 550559.1773396976,\n",
              " 322923.0589821677,\n",
              " 559316.1451657179,\n",
              " 628173.9305401087,\n",
              " 550830.6762818028,\n",
              " 335959.1434903777,\n",
              " 311132.51225447276,\n",
              " 256405.07061918944,\n",
              " 320195.61373238603,\n",
              " 344301.7528210298,\n",
              " 380428.17889833363,\n",
              " 284408.01202616416,\n",
              " 340720.899040922,\n",
              " 255994.24732252548,\n",
              " 594848.8440086461,\n",
              " 647967.4006575574,\n",
              " 276571.99488322105,\n",
              " 755599.8984171998,\n",
              " 454330.6898746362,\n",
              " 425585.92594967195,\n",
              " 530367.5255069421,\n",
              " 466689.31608279765,\n",
              " 408826.3604627252,\n",
              " 832028.1079447784,\n",
              " 378348.04892889125,\n",
              " 458832.24857209943,\n",
              " 384963.4982297957,\n",
              " 351787.2646442894,\n",
              " 908178.5609372911,\n",
              " 619349.3672516278,\n",
              " 517495.724903385,\n",
              " 783557.3089339654,\n",
              " 902683.1840647719,\n",
              " 402922.83423346246,\n",
              " 258553.90520447525,\n",
              " 395603.99313241424,\n",
              " 479107.22062140534,\n",
              " 245752.22148615934,\n",
              " 412792.66115902795,\n",
              " 472738.47616265103,\n",
              " 570861.2644868086,\n",
              " 673464.3149965842,\n",
              " 541061.0360462639,\n",
              " 1126265.469660774,\n",
              " 903831.7705054446,\n",
              " 872375.9489410768,\n",
              " 592762.5006462086,\n",
              " 655371.0434667494,\n",
              " 591166.1311234097,\n",
              " 488425.85274061246,\n",
              " 647736.0700624667,\n",
              " 367225.2329455844,\n",
              " 333785.35637646355,\n",
              " 357127.4101379194,\n",
              " 364651.9744450627,\n",
              " 343173.4182700984,\n",
              " 280603.1075180372,\n",
              " 310979.66088534467,\n",
              " 448968.1416809337,\n",
              " 463181.58019664016,\n",
              " 622812.9500944341,\n",
              " 397019.7953469821,\n",
              " 463909.76521518576,\n",
              " 573477.127516725,\n",
              " 423350.46364424104,\n",
              " 410649.746777342,\n",
              " 355992.8289573191,\n",
              " 672475.3312911124,\n",
              " 345150.79851962905,\n",
              " 255043.96147417402,\n",
              " 310521.6135431979,\n",
              " 477461.16497424623,\n",
              " 535568.140002749,\n",
              " 671224.8995549855,\n",
              " 472711.7427400691,\n",
              " 470223.3321802704,\n",
              " 272783.2890068504,\n",
              " 431836.7490712968,\n",
              " 352528.6000433992,\n",
              " 349380.1903390759,\n",
              " 374089.3111243726,\n",
              " 656000.4549513574,\n",
              " 1494630.679167776,\n",
              " 1301677.7735270073,\n",
              " 264670.65770159673,\n",
              " 487634.78755465534,\n",
              " 493541.33074133657,\n",
              " 1593347.43996018,\n",
              " 459970.6269744803,\n",
              " 462875.4341513624,\n",
              " 321206.6658689921,\n",
              " 383779.60624548636,\n",
              " 520779.6883154321,\n",
              " 758315.6094154817,\n",
              " 790018.8287484986,\n",
              " 310382.3016325562,\n",
              " 510578.24996276456,\n",
              " 309713.024154157,\n",
              " 510563.73358236504,\n",
              " 1380497.304193988,\n",
              " 361111.5337181069,\n",
              " 422260.592118534,\n",
              " 456058.67209333996,\n",
              " 361111.5337181069,\n",
              " 327694.653874522,\n",
              " 704306.0876528217,\n",
              " 797480.4872751482,\n",
              " 346952.0473269597,\n",
              " 369402.3053090637,\n",
              " 361290.82875361334,\n",
              " 1691531.8757533773,\n",
              " 535956.9651324985,\n",
              " 502957.29269952024,\n",
              " 452582.3942206011,\n",
              " 513259.32058450964,\n",
              " 749168.5493715445,\n",
              " 344664.23971914884,\n",
              " 1288492.89011971,\n",
              " 883222.2161147303,\n",
              " 461466.3608675752,\n",
              " 355053.70480289654,\n",
              " 481469.69435650576,\n",
              " 717781.2393468134,\n",
              " 298802.13954600034,\n",
              " 347238.4023816459,\n",
              " 398848.6268281237,\n",
              " 351928.51624665677,\n",
              " 357568.67017318314,\n",
              " 2597814.8232202763,\n",
              " 346588.3932038925,\n",
              " 441831.8805240974,\n",
              " 461069.38316549675,\n",
              " 597455.5492904471,\n",
              " 417307.3448623045,\n",
              " 469812.31496935186,\n",
              " 308464.96895437856,\n",
              " 521998.5123280948,\n",
              " 558051.6899877208,\n",
              " 718303.1195261417,\n",
              " 858461.5729323658,\n",
              " 537414.206595802,\n",
              " 432596.0204632419,\n",
              " 729829.514033321,\n",
              " 352899.7891630229,\n",
              " 349380.1903390759,\n",
              " 523749.9966402525,\n",
              " 507766.6780346616,\n",
              " 465727.51552718075,\n",
              " 897839.1794789867,\n",
              " 370239.02821386367,\n",
              " 3360638.0768143754,\n",
              " 635441.3060813424,\n",
              " 763805.9847202896,\n",
              " 1081281.8496368295,\n",
              " 506287.15244781534,\n",
              " 673669.9118881297,\n",
              " 918742.6914757992,\n",
              " 349874.36566253315,\n",
              " 719682.8005405859,\n",
              " 435766.1656549483,\n",
              " 472760.9558302574,\n",
              " 341614.67745981197,\n",
              " 289928.5751701361,\n",
              " 436981.4442840756,\n",
              " 416740.3213680746,\n",
              " 1371975.3940477509,\n",
              " 304461.5556995143,\n",
              " 346168.96125854936,\n",
              " 532783.7947097614,\n",
              " 364041.9460621955,\n",
              " 313354.8441145824,\n",
              " 506191.1750654548,\n",
              " 367242.9525825145,\n",
              " 442693.34796793124,\n",
              " 485391.62420438876,\n",
              " 448069.26097847504,\n",
              " 370476.5912836091,\n",
              " 641178.332853425,\n",
              " 352992.7910012573,\n",
              " 315985.74862441735,\n",
              " 789222.4473685793,\n",
              " 441242.01622105745,\n",
              " 259041.5302245176,\n",
              " 349020.725110959,\n",
              " 656000.4549513574,\n",
              " 654843.2504137371,\n",
              " 491227.2260992655,\n",
              " 450060.7366282272,\n",
              " 452101.21820207435,\n",
              " 578016.001867511,\n",
              " 472207.51126574626,\n",
              " 537099.205991283,\n",
              " 331229.71209718473,\n",
              " 578020.8594605215,\n",
              " 344108.54026442097,\n",
              " 809419.507293797,\n",
              " 448968.1416809337,\n",
              " 388052.1193352674,\n",
              " 333882.4319693537,\n",
              " 330288.6060491913,\n",
              " 368155.9315637733,\n",
              " 289850.4011225389,\n",
              " 853620.6443124838,\n",
              " 1626408.6936440445,\n",
              " 952111.9835474326,\n",
              " 446247.0006137251,\n",
              " 814040.004720077,\n",
              " 462719.28906442015,\n",
              " 798598.4507615453,\n",
              " 345994.89506449626,\n",
              " 401552.3971985037,\n",
              " 492762.4543750988,\n",
              " 264670.65770159673,\n",
              " 299326.37375990825,\n",
              " 460245.4793276954,\n",
              " 463181.58019664016,\n",
              " 572654.4410811359,\n",
              " 298772.8074216448,\n",
              " 511948.3060313872,\n",
              " 255994.24732252548,\n",
              " 665410.5436620966,\n",
              " 294200.36073371896,\n",
              " 498334.95168488,\n",
              " 298785.3772098242,\n",
              " 390827.04705825786,\n",
              " 481350.03974191076,\n",
              " 611838.0140161192,\n",
              " 473615.5594095642,\n",
              " 925705.6266860365,\n",
              " 255864.07559076985,\n",
              " 1646983.5955065049,\n",
              " 473830.2784419408,\n",
              " 438237.3808879675,\n",
              " 576289.7152017726,\n",
              " 679896.3922581405,\n",
              " 619930.8415356802,\n",
              " 341957.8589902431,\n",
              " 460350.84111170965,\n",
              " 471277.0316397229,\n",
              " 727870.3730003752,\n",
              " 283364.8377774773,\n",
              " 365872.77539413155,\n",
              " 472543.7627487155,\n",
              " 626413.2349021994,\n",
              " 339092.9753709174,\n",
              " 868905.9366328636,\n",
              " 558339.9578196398,\n",
              " 927390.5699945766,\n",
              " 975121.7411748002,\n",
              " 637827.4689828088,\n",
              " 370116.657426414,\n",
              " 798132.845651313,\n",
              " 357984.5924731299,\n",
              " 569379.7409964765,\n",
              " 675981.0806510616,\n",
              " 330350.7540766473,\n",
              " 755030.7157415845,\n",
              " 400148.4366336703,\n",
              " 982252.5635234448,\n",
              " 385199.49786949955,\n",
              " 498856.3885759726,\n",
              " 661230.9492348537,\n",
              " 584989.1924414204,\n",
              " 352627.2433948095,\n",
              " 545105.694975442,\n",
              " 378468.5814152171,\n",
              " 339259.4159354081,\n",
              " 548714.7427626334,\n",
              " 385635.1821498184,\n",
              " 416923.0192427489,\n",
              " 371328.2679030592,\n",
              " 709291.6071124779,\n",
              " 641372.2182713876,\n",
              " 433721.7681283431,\n",
              " 460938.3491758245,\n",
              " 458054.70149790385,\n",
              " 299807.9357906943,\n",
              " 491791.64645175333,\n",
              " 428905.3614143121,\n",
              " 464098.3527980983,\n",
              " 561373.4319424803,\n",
              " 387061.69387030444,\n",
              " 378326.84423581674,\n",
              " 406448.9747719799,\n",
              " 1379838.2844590428,\n",
              " 385199.49786949955,\n",
              " 345949.2720941571,\n",
              " 1192701.012579216,\n",
              " 669098.8720527103,\n",
              " 383487.2884476999,\n",
              " 433688.2551400408,\n",
              " 474476.2178197071,\n",
              " 656149.5120945816,\n",
              " 455786.44626742316,\n",
              " 391703.63660292554,\n",
              " 435848.01607539767,\n",
              " 463181.58019664016,\n",
              " 425585.92594967195,\n",
              " 483818.07671955944,\n",
              " 470363.6664906056,\n",
              " 349173.97556298104,\n",
              " 473803.8383363643,\n",
              " 612448.9517195688,\n",
              " 421634.1282002734,\n",
              " 267473.79348728684,\n",
              " 381739.9406264009,\n",
              " 461651.47908510454,\n",
              " 450120.4572018536,\n",
              " 1086548.0256124807,\n",
              " 455296.5537596929,\n",
              " 397811.4132465453,\n",
              " 563596.4037364518,\n",
              " 332671.7604047696,\n",
              " 669839.1135729958,\n",
              " 406310.2440349223,\n",
              " 477482.6462941303,\n",
              " 485242.1138862643,\n",
              " 485290.33558806643,\n",
              " 558879.0295713281,\n",
              " 333892.1131590344,\n",
              " 608994.7308881064,\n",
              " 513743.4476455717,\n",
              " 700866.5676609663,\n",
              " 532258.1031383611,\n",
              " 513159.1687472021,\n",
              " 491515.87210867304,\n",
              " 521676.64924974844,\n",
              " 385488.2130425579,\n",
              " 364609.7993243038,\n",
              " 351817.6084527496,\n",
              " 653405.7834919865,\n",
              " 381252.77484379534,\n",
              " 359994.1364922998,\n",
              " 273376.49902817194,\n",
              " 369346.5179937038,\n",
              " 383886.5649643705,\n",
              " 832028.1079447784,\n",
              " 2443423.6213190597,\n",
              " 448755.2376676841,\n",
              " 1165315.239334012,\n",
              " 500408.7274039433,\n",
              " 265673.9772613269,\n",
              " 480943.7581095358,\n",
              " 448826.9507594789,\n",
              " 429753.4639614597,\n",
              " 672779.8195926088,\n",
              " 379403.8529141383,\n",
              " 826789.6871926257,\n",
              " 372393.7992692914,\n",
              " 275543.3214986325,\n",
              " 463325.54420936375,\n",
              " 637817.4576922307,\n",
              " 995344.3800488074,\n",
              " 374655.5419265575,\n",
              " 709138.0282484653,\n",
              " 451503.66526938335,\n",
              " 354236.12849852274,\n",
              " 539546.3001797578,\n",
              " 978208.3783099063,\n",
              " 433564.92073882127,\n",
              " 473615.5594095642,\n",
              " 349173.97556298104,\n",
              " 455510.7633729984,\n",
              " 1208598.6889614572,\n",
              " 445838.03449436155,\n",
              " 493817.78870463016,\n",
              " 392460.8580796536,\n",
              " 458060.8505520419,\n",
              " 314666.38921448716,\n",
              " 453315.82885296055,\n",
              " 302286.13356971205,\n",
              " 335735.7139266584,\n",
              " 344553.05355045974,\n",
              " 389929.1795679734,\n",
              " 446256.15396629006,\n",
              " 627590.1023376902,\n",
              " 511037.4463487126,\n",
              " 334579.80333701835,\n",
              " 752748.8013904929,\n",
              " 652797.2424064926,\n",
              " 718138.766367709,\n",
              " 349676.1414161389,\n",
              " 423350.46364424104,\n",
              " 657500.9943096313,\n",
              " 1895515.9906178615,\n",
              " 494601.19111747853,\n",
              " 683879.9964001426,\n",
              " 368225.9254550767,\n",
              " 368457.5987784579,\n",
              " 346037.09529457276,\n",
              " 703793.1389199125,\n",
              " 476262.9941909369,\n",
              " 318026.35811203317,\n",
              " 527498.0380153196,\n",
              " 346940.9037011475,\n",
              " 558767.1005989041,\n",
              " 793303.1339999102,\n",
              " 1037630.366505306,\n",
              " 327208.34686614043,\n",
              " 534942.0702827194,\n",
              " 1198938.9951132007,\n",
              " 463181.58019664016,\n",
              " 805194.5060022045,\n",
              " 623991.9761888146,\n",
              " 459226.97006114747,\n",
              " 821728.8470887752,\n",
              " 711889.3966451667,\n",
              " 253542.2494217791,\n",
              " 375060.6475028247,\n",
              " 285457.1082666374,\n",
              " 436351.49211846065,\n",
              " 540143.8547194663,\n",
              " 336329.1786711669,\n",
              " 497552.6632802356,\n",
              " 539164.3563883405,\n",
              " 408899.37915486755,\n",
              " 497859.1372874941,\n",
              " 356651.3811586491,\n",
              " 837623.544036071,\n",
              " 341777.4975088962,\n",
              " 374836.037148548,\n",
              " 380043.90477012785,\n",
              " 1197156.0128920414,\n",
              " 460372.6142154731,\n",
              " 281603.66209149564,\n",
              " 284607.1160892041,\n",
              " 465024.59418378666,\n",
              " 820071.8379715423,\n",
              " 474509.9597620543,\n",
              " 669362.162539469,\n",
              " 536597.5317801007,\n",
              " 449477.5375594016,\n",
              " 990295.4043593812,\n",
              " 280767.4795867888,\n",
              " 911800.5003999277,\n",
              " 637373.4423144722,\n",
              " 507905.5578230462,\n",
              " 1019562.4031362329,\n",
              " 461216.26618809224,\n",
              " 276953.7173095221,\n",
              " 841610.5721851037,\n",
              " 337449.6025364277,\n",
              " 633147.4400693065,\n",
              " 1487920.3912112485,\n",
              " 349435.9874604653,\n",
              " 500665.24193189037,\n",
              " 448785.5719070764,\n",
              " 366991.39941948163,\n",
              " 253759.89816858235,\n",
              " 870699.4376796375,\n",
              " 440103.5388228603,\n",
              " 282313.82981943624,\n",
              " 470060.67202910385,\n",
              " 353552.07835716556,\n",
              " 280839.9529210362,\n",
              " 492512.94719343504,\n",
              " 357521.16824549885,\n",
              " 416092.21561833285,\n",
              " 392510.0640038482,\n",
              " 476669.72663494304,\n",
              " 483391.4175908781,\n",
              " 544686.2618482683,\n",
              " 784121.6590248875,\n",
              " 334061.7852993614,\n",
              " 326443.6085593998,\n",
              " 381252.77484379534,\n",
              " 383779.60624548636,\n",
              " 327096.9003971391,\n",
              " 457272.48901262676,\n",
              " 778179.3260482607,\n",
              " 498420.69835277204,\n",
              " 850085.5896869823,\n",
              " 838599.5760399192,\n",
              " 472555.10555808985,\n",
              " 440957.75740065746,\n",
              " 481096.1803032647,\n",
              " 314931.340397159,\n",
              " 402064.98204697174,\n",
              " 439794.8645528886,\n",
              " 317900.9113069682,\n",
              " 471703.3968469466,\n",
              " 669362.162539469,\n",
              " 422684.6274669769,\n",
              " 409159.99541999685,\n",
              " 460567.45478753344,\n",
              " 413050.3943501047,\n",
              " 1040581.1601538452,\n",
              " 801147.9636383693,\n",
              " 758226.6568767458,\n",
              " 368343.4918572876,\n",
              " 458054.70149790385,\n",
              " 401450.03475882026,\n",
              " 577572.987342771,\n",
              " 265212.4044339668,\n",
              " 389785.0393815086,\n",
              " 355748.3240140454,\n",
              " 313963.5827456311,\n",
              " 355684.6470350378,\n",
              " 287214.2381662842,\n",
              " 412141.8176301221,\n",
              " 593470.155323203,\n",
              " 309231.29579050996,\n",
              " 441442.24593456334,\n",
              " 520686.8470826358,\n",
              " 486631.20458492043,\n",
              " 352205.02212912537,\n",
              " 335806.3318754677,\n",
              " 285753.3182279662,\n",
              " 540246.7273782823,\n",
              " 472413.17862952163,\n",
              " 1747467.666052666,\n",
              " 459226.97006114747,\n",
              " 2323173.0907005984,\n",
              " 675825.9193238796,\n",
              " 1020458.031159336,\n",
              " 620445.2385816706,\n",
              " 417554.4365572186,\n",
              " 455835.2727542766,\n",
              " 958375.2679179902,\n",
              " 685209.4399832542,\n",
              " 475866.6221876294,\n",
              " 473875.9274014017,\n",
              " 733949.5880021583,\n",
              " 499824.75083685876,\n",
              " 383728.37321477383,\n",
              " 402472.5566651408,\n",
              " 363829.67096730846,\n",
              " 470196.9534910058,\n",
              " 332556.12108484627,\n",
              " 732410.0380671652,\n",
              " 507670.7470564454,\n",
              " 798132.845651313,\n",
              " 691372.0963782823,\n",
              " 509206.8815311372,\n",
              " 448741.48087060906,\n",
              " 484974.47221271484,\n",
              " 489714.0458013894,\n",
              " 501192.64835599606,\n",
              " 565244.4322355725,\n",
              " 307817.51190783276,\n",
              " 1070010.625818947,\n",
              " 310141.0208422253,\n",
              " 583251.8031196448,\n",
              " 275778.55547350325,\n",
              " 1780257.5722795918,\n",
              " 850929.8732403724,\n",
              " 625790.8328236659,\n",
              " 509201.51840255887,\n",
              " 647884.2432875948,\n",
              " 562575.7250580753,\n",
              " 347487.5728858619,\n",
              " 533714.6200268188,\n",
              " 463907.3085287709,\n",
              " 983967.8325922224,\n",
              " 377490.9091578562,\n",
              " 498440.45164259686,\n",
              " 990830.5091475594,\n",
              " 535673.1599769439,\n",
              " 455937.32919836027,\n",
              " 449358.36620169785,\n",
              " 1060079.9191854768,\n",
              " 319620.04275769455,\n",
              " 634651.0561101392,\n",
              " 788572.6171653775,\n",
              " 319620.04275769455,\n",
              " 624033.8139687962,\n",
              " 590254.2338452789,\n",
              " 399770.05985630053,\n",
              " 473428.6106547404,\n",
              " 623127.630805065,\n",
              " 432833.8009673282,\n",
              " 349676.1414161389,\n",
              " 531681.4709749834,\n",
              " 275778.55547350325,\n",
              " 346429.80110413744,\n",
              " 470058.0174413783,\n",
              " 534105.4393937486,\n",
              " 444960.0037971645,\n",
              " 819270.224394153,\n",
              " 410603.6023010214,\n",
              " 298452.58168299985,\n",
              " 322324.26703073864,\n",
              " 470363.6664906056,\n",
              " 740623.5735649721,\n",
              " 756958.3376774954,\n",
              " 370239.02821386367,\n",
              " 292943.17941256723,\n",
              " 386580.95624589984,\n",
              " 271728.6482754667,\n",
              " 860163.4199216844,\n",
              " 400670.34702165436,\n",
              " 282991.5234417021,\n",
              " 337464.5588115632,\n",
              " 488614.5616599671,\n",
              " 489738.94178188295,\n",
              " 470363.6664906056,\n",
              " 1138001.2598658854,\n",
              " 1032171.109448145,\n",
              " 1168099.6401111404,\n",
              " 431347.5309475755,\n",
              " 583359.2148125481,\n",
              " 368310.5548095931,\n",
              " 510215.4664656393,\n",
              " 357596.1187795626,\n",
              " 389543.92306095955,\n",
              " 347159.6128376603,\n",
              " 812841.5787199757,\n",
              " 464202.1245379928,\n",
              " 356170.7527035112,\n",
              " 392715.3027733609,\n",
              " 296197.522480003,\n",
              " 530326.831681006,\n",
              " 480888.0468689123,\n",
              " 424761.085156731,\n",
              " 528948.0127339907,\n",
              " 272682.6628230723,\n",
              " 636668.3805747239,\n",
              " 524951.2064609354,\n",
              " 453410.78287040215,\n",
              " 472207.51126574626,\n",
              " 298259.5865822928,\n",
              " 361134.58426769724,\n",
              " 1152073.4429987029,\n",
              " 772124.4157391505,\n",
              " 441103.7879831289,\n",
              " 320301.2017302022,\n",
              " 346721.57752509904,\n",
              " 1007026.0499149575,\n",
              " 551989.242759933,\n",
              " 427228.81729022675,\n",
              " 276563.7053512105,\n",
              " 379491.9441668046,\n",
              " 296810.6928097206,\n",
              " 859828.1446281088,\n",
              " 253226.65762427807,\n",
              " 319695.6761135516,\n",
              " 295860.54114217986,\n",
              " 469812.31496935186,\n",
              " 479774.36220701976,\n",
              " 597902.0340717973,\n",
              " 574076.6220455184,\n",
              " 384458.9390505226,\n",
              " 473941.8668346889,\n",
              " 566059.3283666811,\n",
              " 481091.7960158772,\n",
              " 471166.63675669825,\n",
              " 619349.3672516278,\n",
              " 512271.5685246969,\n",
              " 781546.6892247008,\n",
              " 387601.18429522973,\n",
              " 315374.5445689846,\n",
              " 465735.90791601577,\n",
              " 591327.1672706449,\n",
              " 472149.627315907,\n",
              " 493219.9190765666,\n",
              " 934002.4661085854,\n",
              " 523113.0108380821,\n",
              " 739599.7545797452,\n",
              " 628555.6832824985,\n",
              " 837028.9524417215,\n",
              " 276172.5094490719,\n",
              " 478852.4869110695,\n",
              " 470933.4783066562,\n",
              " 814701.8713835838,\n",
              " 858667.533841532,\n",
              " 275968.01512701315,\n",
              " 258553.90520447525,\n",
              " 487531.9032069877,\n",
              " 300055.25905220956,\n",
              " 712065.5046954078,\n",
              " 389577.73302054557,\n",
              " 477578.85328502714,\n",
              " 518071.4233751492,\n",
              " 383779.376553855,\n",
              " 295860.54114217986,\n",
              " 293702.72339346533,\n",
              " 320754.62996550027,\n",
              " 629834.5065337887,\n",
              " 285874.17051843606,\n",
              " 372393.79617598094,\n",
              " 475654.7684144295,\n",
              " 389956.88973736484,\n",
              " 521676.64924974844,\n",
              " 370712.1112916162,\n",
              " 389543.92306095955,\n",
              " 464202.1245379928,\n",
              " 352254.7406378233,\n",
              " 1190125.7764148826,\n",
              " 625412.8814684477,\n",
              " 328853.803843982,\n",
              " 456260.094478499,\n",
              " 753942.2790120171,\n",
              " 638231.6028067478,\n",
              " 267215.91801754764,\n",
              " 468841.03159089613,\n",
              " 390827.04705825786,\n",
              " 298761.8698183199,\n",
              " 856573.8476035945,\n",
              " 473317.011833114,\n",
              " 554492.1587040295,\n",
              " 477632.4279412494,\n",
              " 668627.0426698638,\n",
              " 583040.6741847249,\n",
              " 847494.939484108,\n",
              " 666328.4737982161,\n",
              " 793008.0106995313,\n",
              " 379832.68212153815,\n",
              " 1037059.0902968566,\n",
              " 616486.6777485138,\n",
              " 775160.2437387038,\n",
              " 460422.98408724077,\n",
              " 466185.4747960029,\n",
              " 379403.8529141383,\n",
              " 464202.1245379928,\n",
              " 375060.6475028247,\n",
              " 783557.3089339654,\n",
              " 525527.1367790728,\n",
              " 488057.2450104732,\n",
              " 277591.1208814806,\n",
              " 275778.55547350325,\n",
              " 298647.55033075117,\n",
              " 806346.9153116479,\n",
              " 654776.7306055591,\n",
              " 461418.7329244018,\n",
              " 360093.3884965647,\n",
              " 462569.63800398086,\n",
              " 368155.9315637733,\n",
              " 655111.9993373142,\n",
              " 276209.54082949145,\n",
              " 650631.6587756252,\n",
              " 528254.0953270019,\n",
              " 351627.08984969946,\n",
              " 281062.1286441646,\n",
              " 480926.98073258635,\n",
              " 503615.07164126844,\n",
              " 376402.3162606839,\n",
              " 690852.8505720233,\n",
              " 335735.7139266584,\n",
              " 389577.73302054557,\n",
              " 549059.5739026346,\n",
              " 301650.35799460876,\n",
              " 570956.5476036763,\n",
              " 686874.0748533903,\n",
              " 702054.2819106581,\n",
              " 488537.2231270485,\n",
              " 422239.4938433624,\n",
              " 707386.240517697,\n",
              " 507743.8377447007,\n",
              " 654776.7306055591,\n",
              " 1569194.7228356441,\n",
              " 532273.0481116188,\n",
              " 342426.2560432697,\n",
              " 699511.0063115022,\n",
              " 829676.3750140697,\n",
              " 341012.1365628296,\n",
              " 405960.2030875699,\n",
              " 376408.3970220388,\n",
              " 294938.34112706874,\n",
              " 509898.1130169837,\n",
              " 502346.9038844902,\n",
              " 407594.6823635835,\n",
              " 490966.4607328517,\n",
              " 327969.4001334096,\n",
              " 371127.74416919134,\n",
              " 253954.32845303995,\n",
              " 351787.2646442894,\n",
              " 345949.2720941571,\n",
              " 330772.5732527323,\n",
              " 345236.5719490353,\n",
              " 333420.3185344653,\n",
              " 819247.8533372246,\n",
              " 420362.95569735556,\n",
              " 443011.9868001544,\n",
              " 706500.2189819384,\n",
              " 355945.416352872,\n",
              " 253226.65762427807,\n",
              " 370415.05415966717,\n",
              " 291374.1479009978,\n",
              " 582843.6204399827,\n",
              " 300007.59795630554,\n",
              " 520107.32162463956,\n",
              " 814753.0113005148,\n",
              " 570620.971110104,\n",
              " 559420.5572905638,\n",
              " 501455.6943356987,\n",
              " 268008.1907479945,\n",
              " 943900.4707460994,\n",
              " 639637.5375683043,\n",
              " 858461.5729323658,\n",
              " 324473.55666184163,\n",
              " 463345.9693026219,\n",
              " 808042.8600749018,\n",
              " 509678.9457317882,\n",
              " 255597.5287508612,\n",
              " 1163304.4789512875,\n",
              " 310406.925160818,\n",
              " 635072.5958281534,\n",
              " 470060.67202910385,\n",
              " 761935.7534762094,\n",
              " 541140.2401505259,\n",
              " 451503.66526938335,\n",
              " 458054.70149790385,\n",
              " 444780.15476791566,\n",
              " 558339.5164731037,\n",
              " 1327229.2736850535,\n",
              " 476291.9995469062,\n",
              " 831584.8902046965,\n",
              " 482640.39790969697,\n",
              " 380182.93313049903,\n",
              " 277255.88212782895,\n",
              " 437772.04753013904,\n",
              " 545344.0255667312,\n",
              " 487918.84248466225,\n",
              " 454786.96023067087,\n",
              " 296810.6928097206,\n",
              " 363621.03018973785,\n",
              " 350294.6378937431,\n",
              " 508202.2089204123,\n",
              " 561866.5052877056,\n",
              " 284622.9118355519,\n",
              " 378528.2675792928,\n",
              " 503206.234333512,\n",
              " 624033.8139687962,\n",
              " 973658.9531134013,\n",
              " 669673.3819880645,\n",
              " 357151.85195570823,\n",
              " 787878.5026727136,\n",
              " 704717.8299096932,\n",
              " 837200.5057597274,\n",
              " 352388.5429515426,\n",
              " 2187080.5535395234,\n",
              " 368163.0090151553,\n",
              " 380172.2518146644,\n",
              " 506640.0970963383,\n",
              " 332640.8475415607,\n",
              " 356170.1887975809,\n",
              " 552602.8868101777,\n",
              " 659583.3391958993,\n",
              " 696998.5013525699,\n",
              " 274909.897413265,\n",
              " 352627.2433948095,\n",
              " 545352.9163485889,\n",
              " 2325930.716011178,\n",
              " 553512.2291659523,\n",
              " 465206.4731080508,\n",
              " 917553.7284869,\n",
              " 630471.7921603174,\n",
              " 550084.3687438753,\n",
              " 790848.2314106468,\n",
              " 740484.2383782824,\n",
              " 451503.66526938335,\n",
              " 293738.4434262844,\n",
              " 442231.609474899,\n",
              " 661771.8201925732,\n",
              " 553894.2829743201,\n",
              " 283943.7406331174,\n",
              " 298686.3389429681,\n",
              " 561153.7568239971,\n",
              " 414891.3478081092,\n",
              " 677223.7199913741,\n",
              " 490889.04943720554,\n",
              " 924667.8504184197,\n",
              " 378524.7915277417,\n",
              " 292651.5383074652,\n",
              " 392149.1984522981,\n",
              " 286960.293573067,\n",
              " 361111.5337181069,\n",
              " 341012.1365628296,\n",
              " 395669.0659229892,\n",
              " 924205.4657532232,\n",
              " 580876.0531223088,\n",
              " 363107.77034276375,\n",
              " 505899.9455221788,\n",
              " 663307.7145061246,\n",
              " 255438.38341986842,\n",
              " 536195.6181216143,\n",
              " 365008.3108955531,\n",
              " 643344.5575074335,\n",
              " 632526.0042093898,\n",
              " 463287.1144616104,\n",
              " 292044.0096180249,\n",
              " 435496.97842548887,\n",
              " 350150.8105173554,\n",
              " 881638.3732059791,\n",
              " 355858.0508973019,\n",
              " 566934.8155209598,\n",
              " 413640.6923860436,\n",
              " 392460.8580796536,\n",
              " 351734.7434842339,\n",
              " 345442.57322104264,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "bagging_predict"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}